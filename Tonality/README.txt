АНАЛИЗАТОР ТОНАЛЬНОСТИ ТЕКСТА

1. РЕШАЕМАЯ ЗАДАЧА


Данная программа предназначена для анализа эмоциональной тональности текстов на русском языке. 
Она выполняет следующие задачи:

- Токенизация  (разбивка на отдельные слова)
- Лемматизация слов с определением частей речи
- Фильтрация шумовых слов (служебные части речи)
- Объединение слов в значимые фразы с модификаторами
- Учет модификаторов тональности (усилители, ослабители, отрицания)
- Анализ эмоциональной окраски с использованием тонального словаря
- Оценка тональности всего текста
- Генерация детальных отчетов и визуализации


2. АЛГОРИТМ РАБОТЫ МОДИФИКАТОРОВ ТОНАЛЬНОСТИ


2.1. Принцип работы

Сначала происходит токенизация текста, т.е разделение текста на отдельные токены(слова), удаление знаков препинания, приведение текста к нижнему регистру. Затем следует лингвистический анализ, в ходе которого слова приводятся к начальной форме (лемматизация) и определяются их части речи. На следующем этапе программа фильтрует шумовые слова, удаляя служебные части речи такие, как предлоги, союзы и местоимения, но сохраняя важные для анализа тональности модификаторы "не" и "ни". Особенностью программы является объединение слов в смысловые фразы, где модификаторы соединяются с основными словами, например, "не" + "хороший" образует фразу "не хороший". Ключевой этап - анализ тональности с использованием словаря эмоциональной окраски слов    "kartaslovsent", из словаря берется значение value (значение тональности). Программа не просто определяет тональность отдельных слов, но и учитывает влияние модификаторов: 
- Усилители ("очень", "крайне" и др.): умножают значение следующего слова на 2
- Ослабители ("слегка", "довольно" и др.): умножают значение следующего слова на 0.5  
- Отрицания ("не", "ни"): инвертируют знак следующего слова (умножают на -1)
 Все слова и фразы классифицируются на положительные, отрицательные и нейтральные основываясь на пороговых значениях параметра value. Программа генерирует четыре типа выходных данных: детальный анализ всех этапов обработки текста, таблицу статистики с разделением на значимые и шумовые слова, статистику с количественными показателями и визуализацию в виде диаграмм. На выход помимо файлов подается итоговое значение тональности текстов

2.2. Обоснование коэффициентов

1) Для слов меняющих окраску следующего слова.

Коэффициенты подобраны эмпирически на основе лингвистических познаниях автора проекта:

- Усилители (×2): значительно усиливают эмоциональную окраску
- Ослабители (×0.5): ослабляют, но не полностью нейтрализуют эмоцию
- Отрицания (×(-1)): полностью инвертируют эмоциональную оценку

2) Для тональности леммы.

Коэффициенты подобраны деление отрезка значений параметра value на три приблизительно равные группы:

- Положительная: value > 0.33
- Нейтральная: -0.33 <= value <= 0.33
- Отрицательная: value < 0.33

3) Для общей тональности текста:

Коэффициенты подобраны на основе анализа тестов:

- Крайне Положительный:  > 0.5
- Положительный: > 0.1
- Нейтральный: от -0.1 до 0.1
- Отрицательный: < -0.1
- Крайне отрицательный: < -0.50


3. ОСНОВНЫЕ КОМПОНЕНТЫ ПРОГРАММЫ


ИСПОЛЬЗУЕМЫЕ БИБЛИОТЕКИ:

pymorphy2 - морфологический анализатор для русского языка
csv - работа с CSV-файлами (тональный словарь)
os - работа с файловой системой
collections - расширенные структуры данных
re - регулярные выражения для токенизации
matplotlib - визуализация результатов
numpy - математические операции
sys - управление выполнением программы

ОСНОВНЫЕ ФУНКЦИИ ПРОГРАММЫ:

segment_and_tokenize(text)
Назначение: Сегментация текста на токены (слова)
Вход: строка текста
Выход: список токенов в нижнем регистре

lemmatize_tokens(tokens)
Назначение: Лемматизация токенов и определение частей речи
Вход: список токенов
Выход: список кортежей (лемма, часть_речи)

get_part_of_speech(tag)
Назначение: Преобразование тегов pymorphy2 в сокращенные русские обозначения
Вход: тег части речи от pymorphy2
Выход: сокращенное русское обозначение части речи

remove_noise_words(lemmas_with_pos)
Назначение: Фильтрация шумовых слов (служебных частей речи)
Вход: список лемм с частями речи
Выход: кортеж (отфильтрованные леммы, шумовые слова)

combine_words(lemmas_with_pos)
Назначение: Объединение модификаторов с основными словами в фразы
Вход: список лемм с частями речи
Выход: список слов и фраз

load_tone_dict(dict_path='kartaslovsent.csv')
Назначение: Загрузка словаря тональности
Вход: путь к CSV файлу словаря
Выход: словарь {слово: значение_тональности}

calculate_phrase_tones(phrases, tone_dict)
Назначение: Расчет тональности для фраз с учетом модификаторов
Вход: список фраз, словарь тональности
Выход: список кортежей (упорядоченная, но неизменяемая последовательность элементов: фраза, тональность)

get_tone_category(value)
Назначение: Классификация тональности по числовому значению для отдельных слов/фраз
Вход: числовое значение тональности
Выход: текстовый тег ("положительное", "отрицательное", "нейтральное")

tone_category_for_text(value)
Назначение: Классификация общей тональности текста по удельным значениям
Вход: числовое значение удельной тональности
Выход: текстовый тег ("крайне положительный", "положительный", "нейтральный", "отрицательный", "крайне отрицательный")

create_statistics_table(phrases_with_tones, noise_words, tone_dict)
Назначение: Создание статистической таблицы по анализу
Вход: фразы с тональностью, шумовые слова, словарь тональности
Выход: список строк таблицы

calculate_comprehensive_statistics(tokens, lemmas_with_pos, filtered_lemmas, phrases, tone_results, tone_dict, noise_words)
Назначение: Расчет комплексной статистики анализа
Вход: различные данные анализа текста
Выход: словарь со статистическими показателями

create_plots(stats, filename)
Назначение: Создание визуализаций анализа
Вход: статистика, имя файла для сохранения
Выход: PNG файл с графиками


4. ТРЕБОВАНИЯ К СИСТЕМЕ


НЕОБХОДИМЫЕ ФАЙЛЫ:

kartaslovsent.csv - тональный словарь в формате CSV с разделителем ';'
Должен содержать колонки: term, value. Должен находиться в одной директории с исполняемым файлом.
Текстовые файлы для анализа (кодировка UTF-8)

МИНИМАЛЬНЫЕ ТРЕБОВАНИЯ:

Python 3.6 или выше, рекомендуется Python 3.10.18
Библиотека pymorphy2 версии 2.0 или выше
Библиотеки: matplotlib, numpy

УСТАНОВКА:

pip install pymorphy2 matplotlib numpy

kartaslovsent.csv по ссылке:
https://github.com/dkulagin/kartaslov/tree/master/dataset/kartaslovsent
 

5. ФОРМАТ РАБОТЫ ПРОГРАММЫ:
 

Пользователь вводит имя текстового файла для анализа

Программа создает четыре выходных файла:

[имя]_analysis.txt - детальный процесс обработки текста
[имя]_table.txt - таблица статистики по фразам и словам
[имя]_statistics.txt - комплексная статистика анализа
[имя]_plots.png - визуализация результатов в виде графиков

Программа выводит информацию о созданных файлах и общую тональность текста.


6. ВЫХОДНЫЕ ДАННЫЕ И ИХ ОПИСАНИЕ


1) Файл [имя]_analysis.txt последовательно отображает каждый этап работы алгоритма. Он начинается токенизации, затем следует раздел лемматизации с определением частей речи, где каждое слово приводится к начальной форме и классифицируется. Далее демонстрируется процесс фильтрации шумовых слов - удаляются служебные части речи. Далее раздел с формированием значимых фраз и расчетом их тональности, где показываются итоговые словосочетания с учетом влияния модификаторов и их финальная эмоциональная оценка. 

2) Файл [имя]_table.txt организует всю полученную информацию в структурированном виде. В таблице представлены шесть ключевых колонок: сами слова и фразы с указанием частей речи для шумовых элементов, статус значимости, частота употребления в тексте, исходное значение тональности из словаря, итоговое значение после применения модификаторов и финальная тональность. 

3) Файл [имя]_statistics.txt демонстрирует статистику по тексту: основные, дополнительные, суммарные показатели, результат - итоговое значение тональности текста.

4) Файл [имя]_plots.png содержит графическое представление данных в виде четырех диаграмм. Две круговые диаграммы в верхней части отображают пропорциональное распределение слов по тональностным категориям - первая показывает общее распределение всех слов текста, вторая - исключительно для значимых слов. Две диаграммы в нижней части демонстрируют нормализованные значения тональности по различным метрикам: левая диаграмма отображает тональность по основным показателям (словоупотребления, словоформы, леммы), правая - по значимым элементам (слова, леммы, фразы). 

5) Итоговое значение тональности текста.


7. ОГРАНИЧЕНИЯ ПРОГРАММЫ


Учет контекста, программа не учитывает:

- Иронию и сарказм
- Многозначность слов в разных контекстах
- Сложные синтаксические конструкции
- Культурные и ситуационные особенности

Лингвистические ограничения:

- Обрабатывает только последовательные модификаторы, не учитывая порядка слов
- Не анализирует сложные словосочетания и идиомы


Технические ограничения:

Зависимость от размера тонального словаря
Точность зависит от правильности лемматизации
Не обрабатывает опечатки и нестандартные написания
Ограниченная обработка сложных модификаторов


8. ОПИCАНИЕ ТЕСТОВ

- test1.txt - текст только с положительными и нейтральными словами
- test2.txt - текст только из отрицательных слов и нейтральных слов  
- test3.txt - текст с равным количеством отрицательных и положительных слов (нейтральный)
- test4.txt - текст с сарказмом
- test5.txt - текст где нейтральный посыл, но из-за отсутствия контекста может восприниматься отрицательно
- test6.txt - текст с двойными модификаторами
- test7.txt - отрывок из Гарри Поттера
- test8.txt - положительный отзыв о ВМК


9. КРАТКО О РЕЗУЛЬТАТАХ


Программа успешно решает задачу анализа тональности русскоязычных текстов, предоставляя:
- Полную цепочку обработки от токенизации до анализа тональности
- Учет лингвистических особенностей (модификаторы, части речи)
- Детальную статистику
- Визуализацию результатов


10. ПРИКЛАДНАЯ ЗАДАЧА

Социологическое исследование. Будут анализироваться тексты по определенным темам и определяться, как люди выражают эмоции в них. (Например: Тема - политика, 70% сообщений на эту тему имеет негативную тональность, в хобби - 80% положительная и тд). РЕшение и подробное описание прикладной задачи находиться в файле "Прикладная_задача.txt".
