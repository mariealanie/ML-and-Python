{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZgN2IsNnmH-"
   },
   "source": [
    "### Обязательные библиотеки:\n",
    "- [Gensim](https://radimrehurek.com/gensim/) — инструмент для решения различных задач NLP (тематическое моделирование, представление текстов, ...);\n",
    "- [Numpy](http://www.numpy.org) — библиотека для векторных вычислений;\n",
    "Для выполнения дополнительных заданий (по желанию)\n",
    "- [Pandas](https://pandas.pydata.org) - библиотека для анализа табличных данных;\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — библилиотека с алгоритмами классического машинного обучения;\n",
    "- [matplotlib](https://matplotlib.org) - библиотека для построения графиков;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxA-zK5OnmIA"
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICOFfqI7nmIB",
    "outputId": "33d60ac0-41fc-437e-9cb9-5d6a254f5f01"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Константы\n",
    "DATA_DIR = 'data'\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5gJDANXnmIB"
   },
   "source": [
    "### Модель, генерирующая вектора слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAkkfYQsnmIC",
    "outputId": "8683d4d7-6030-4124-d55b-87fa9af7b3a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распаковываем архив...\n",
      "Архив успешно распакован\n"
     ]
    }
   ],
   "source": [
    "from utils import download_model\n",
    "\n",
    "download_model(data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HYFLEQo-nmIC"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "wv_embeddings = gensim.models.fasttext.FastTextKeyedVectors.load(\n",
    "    DATA_DIR + \"/model/model.model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a(model, target_word, topn, result_size):\n",
    "    candidates = model.most_similar(target_word, topn=topn)\n",
    "    result = []\n",
    "    used_prefixes = {target_word.lower()}  \n",
    "    for w, score in candidates:\n",
    "        w_lower = w.lower()\n",
    "        if not w_lower.isalpha() and \"-\" not in w_lower:\n",
    "            continue\n",
    "        if target_word.lower() in w_lower:\n",
    "            continue\n",
    "        if w_lower[:3] in used_prefixes:\n",
    "            continue\n",
    "        used_prefixes.add(w_lower[:3])\n",
    "        result.append((w, score))\n",
    "        if len(result) == result_size:\n",
    "            break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_b(model, target_word, filepath, result_size):\n",
    "    base_vec = model[target_word]\n",
    "    base_norm = base_vec / np.linalg.norm(base_vec)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        candidates = file.read().split()\n",
    "    top_results = []\n",
    "    for w in candidates:\n",
    "        if w == target_word or w not in model:\n",
    "            continue\n",
    "        vec = model[w]\n",
    "        vec_norm = vec / np.linalg.norm(vec)\n",
    "        similarity = float(np.dot(base_norm, vec_norm))\n",
    "        if len(top_results) < result_size:\n",
    "            top_results.append((w, similarity))\n",
    "            top_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        else:\n",
    "            if similarity > top_results[-1][1]:\n",
    "                top_results[-1] = (w, similarity)\n",
    "                top_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return top_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат а\n",
      "('маячный', 0.6048486828804016)\n",
      "('мыс', 0.5482443571090698)\n",
      "('утес', 0.5242083072662354)\n",
      "('скала', 0.5140703320503235)\n",
      "('башня', 0.5124934315681458)\n",
      "('обелиски', 0.5116521716117859)\n",
      "('пристань', 0.5099610090255737)\n",
      "('береговый', 0.5064749717712402)\n",
      "('мостик', 0.5064305663108826)\n",
      "('шпиль', 0.5039313435554504)\n",
      "\n",
      "Результат б\n",
      "('светомаяк', 0.5747745633125305)\n",
      "('радиомаяк', 0.5415729284286499)\n",
      "('утес', 0.5242083668708801)\n",
      "('скала', 0.5140702724456787)\n",
      "('башня', 0.5124935507774353)\n",
      "('пристань', 0.5099611878395081)\n",
      "('световоймаяк', 0.4968123435974121)\n",
      "('корабль', 0.4957634210586548)\n",
      "('берег', 0.48608696460723877)\n",
      "('обсерватория', 0.4761872887611389)\n"
     ]
    }
   ],
   "source": [
    "word = \"маяк\"\n",
    "\n",
    "res_a = get_a(wv_embeddings, word, 60, 10)\n",
    "res_b = get_b(wv_embeddings, word, \"text.txt\", 10)\n",
    "\n",
    "\n",
    "print(\"Результат а\")\n",
    "for r in res_a:\n",
    "    print(r)\n",
    "\n",
    "print(\"\\nРезультат б\")\n",
    "for r in res_b:\n",
    "   print(r)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Vector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
